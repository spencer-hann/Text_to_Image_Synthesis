# Text to Image Synthesis

Using NLP feature extraction, and Generative Adversarial Networks to generate images from text descriptions.  

Partial replication of the paper [Generative Adversarial Text to Image Synthesis](https://arxiv.org/pdf/1605.05396.pdf).  
Authors: [Scott Reed](https://github.com/reedscot), Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, Honglak Lee  

## Presentation

For more information this project, read our [presentation](https://github.com/spencer-hann/Text_to_Image_Synthesis/README.pdf).

## Example output

![](https://github.com/spencer-hann/Text_to_Image_Synthesis/blob/master/exp3/fake_samples_epoch_598.png)

## Data sets used

### General Use  

From Caltech and Oxford websites:
 * [Caltech-UCSD Birds-200-2011](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html)  
 
### Preprocessed w/Text descriptions  

From primary author's [github repo](https://github.com/reedscot/icml2016):
 * [Birds from github.com/reedscot/cvpr2016](https://drive.google.com/file/d/0B0ywwgffWnLLZW9uVHNjb2JmNlE/view)
