{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_models.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"BLBhhZEjnr2Q","colab_type":"code","outputId":"a723b79e-396c-4c2c-f371-30f8d9043489","executionInfo":{"status":"ok","timestamp":1552938479655,"user_tz":420,"elapsed":23360,"user":{"displayName":"Spencer Hann","photoUrl":"","userId":"17376529174106278393"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"id":"CfkCiBL8oBIl","colab_type":"code","outputId":"9518cb2b-8fda-48b2-9e58-0c19e5a27e84","executionInfo":{"status":"ok","timestamp":1552938479664,"user_tz":420,"elapsed":23335,"user":{"displayName":"Spencer Hann","photoUrl":"","userId":"17376529174106278393"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["%cd drive/\"My Drive/Text_to_Image_Synthesis\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Text_to_Image_Synthesis\n"],"name":"stdout"}]},{"metadata":{"id":"SD9JYJ1WoVkU","colab_type":"code","outputId":"80ab2e3c-8796-45db-cc2d-11a63e773691","executionInfo":{"status":"ok","timestamp":1552938480869,"user_tz":420,"elapsed":24520,"user":{"displayName":"Spencer Hann","photoUrl":"","userId":"17376529174106278393"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"cell_type":"code","source":["!ls"],"execution_count":3,"outputs":[{"output_type":"stream","text":[" Birds_for_google_colab        dataset.py    models.py\t   train_models.ipynb\n","'Copy of train_models.ipynb'   datatest.py   output\n"," data\t\t\t       gan.py\t     __pycache__\n"],"name":"stdout"}]},{"metadata":{"id":"Fio5IwoRoXyE","colab_type":"code","outputId":"9b498742-5ab1-4696-a833-765b03b0a1c1","executionInfo":{"status":"ok","timestamp":1552938482688,"user_tz":420,"elapsed":26322,"user":{"displayName":"Spencer Hann","photoUrl":"","userId":"17376529174106278393"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"id":"aKyyj2odobdR","colab_type":"code","outputId":"86e50a2e-b7b2-461a-f12a-101b66334165","executionInfo":{"status":"ok","timestamp":1552938485184,"user_tz":420,"elapsed":28799,"user":{"displayName":"Spencer Hann","photoUrl":"","userId":"17376529174106278393"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["import dataset\n","print(dataset.Birds_img_dir)\n","print(dataset.Birds_txt_dir)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["./data/Birds/Caltech-UCSD-Birds-200-2011/CUB_200_2011/images\n","./data/Birds/cub_cvpr/text_c10\n"],"name":"stdout"}]},{"metadata":{"id":"_CUjAlrQFTfp","colab_type":"code","colab":{}},"cell_type":"code","source":["# import datatest\n","# datatest.simple_test()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FMBx2rvotT_L","colab_type":"code","colab":{}},"cell_type":"code","source":["# !python gan.py --cuda --niter=1 --outf \"output\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"xlThYg88te6K","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"tbF9ETWGDjlR","colab_type":"code","colab":{}},"cell_type":"code","source":["class Opt:\n","  def __init__(self):\n","    self.dataset = 'folder' #  , help='cifar10 | lsun | mnist |imagenet | folder | lfw | fake')\n","    self.dataroot = '.' # , help='path to dataset')\n","    self.workers = 2 # , help='number of data loading workers')\n","    self.batchSize = 64 # , help='input batch size')\n","    self.imageSize = 64 # , help='the height / width of the input image to network')\n","    self.nz = 100 # , help='size of the latent z vector')\n","    self.ngf = 64 # )\n","    self.ndf = 64 # )\n","    self.niter = 20 # , help='number of epochs to train for')\n","    self.lr = 0.0004 # , help='learning rate, default=0.0002')\n","    self.beta1 = 0.3 # , help='beta1 for adam. default=0.5')\n","    self.cuda = True # help='enables cuda')\n","    self.ngpu = 1 # , help='number of GPUs to use')\n","    self.netG = '' # , help=\"path to netG (to continue training)\")\n","    self.netD = '' # , help=\"path to netD (to continue training)\")\n","    self.outf = 'output' # , help='folder to output images and model checkpoints')\n","    self.manualSeed = None # , help='manual seed')\n","\n","    self.cls = True # , help='activates cls run')\n","    self.desc_per_img = 10 # , help='# of descriptions per image. max=10')\n","    self.incl_stopwords = False # , help='include word vectors for stopwords in text encodings')\n","    \n","  def display_options(self):\n","    print(\n","      \"self.dataset:\",self.dataset,\n","      \", self.dataroot\",self.dataroot,\n","      \", self.workers\",self.workers,\n","      \", self.batchSize\", self.batchSize,\n","      \", self.imageSize\",self.imageSize,\n","      \", self.nz\",self.nz,\n","      \", self.ngf\",self.ngf,\n","      \", self.ndf\",self.ndf,\n","      \", self.niter\",self.niter,\n","      \", self.lr\",self.lr,\n","      \", self.beta1\",self.beta1,\n","      \", self.cuda\",self.cuda,\n","      \", self.ngpu\",self.ngpu,\n","      \", self.netG\",self.netG,\n","      \", self.netD\",self.netD,\n","      \", self.outf\",self.outf,\n","      \", self.manualSeed\",self.manualSeed,\n","      \", self.cls\",self.cls,\n","      \", self.desc_per_img\",self.desc_per_img,\n","      \", self.incl_stopwords\",self.incl_stopwords\n","    )\n","\n","opt = Opt()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tVEuWdbidZlF","colab_type":"code","colab":{}},"cell_type":"code","source":["# !unzip \"data/Birds_for_google_colab.zip\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"FJ9z7sKRDspj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"e838df31-b6b4-4a9b-843b-30b07e13878b"},"cell_type":"code","source":["#from dataset2 import TTI_Dataset\n","from dataset import Birds\n","from models import Concat, Discriminator, Generator\n","\n","#dataset = TTI_Dataset()\n","dataset = Birds(\n","            img_dir=\"./Birds_for_google_colab/Caltech-UCSD-Birds-200-2011/CUB_200_2011/images\",\n","            txt_dir=\"./Birds_for_google_colab/cub_cvpr/text_c10\",\n","            descriptions_per_image=opt.desc_per_img,\n","            incl_stopwords=opt.incl_stopwords\n","        )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loading Birds dataset in `dataset.py`: descriptions_per_img=10, encoding_dim=1024, incl_stopwords=False\n","Loading images...\n","  loading files... "],"name":"stdout"},{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["done!\n","  creating tensor...\n"],"name":"stdout"},{"output_type":"stream","text":["62it [00:18,  3.51it/s]"],"name":"stderr"}]},{"metadata":{"id":"k3o_hLscDxOC","colab_type":"code","colab":{}},"cell_type":"code","source":["# Fork of dcgan from pytorch.examples.dcgan\n","\n","from __future__ import print_function\n","import argparse\n","import os\n","import time\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","import numpy as np\n","# #from dataset2 import TTI_Dataset\n","# from dataset import Birds\n","# from models import Concat, Discriminator, Generator\n","\n","# parser = argparse.ArgumentParser()\n","# parser.add_argument('--dataset', default='folder' , help='cifar10 | lsun | mnist |imagenet | folder | lfw | fake')\n","# parser.add_argument('--dataroot', default='.', help='path to dataset')\n","# parser.add_argument('--workers', type=int, help='number of data loading workers', default=2)\n","# parser.add_argument('--batchSize', type=int, default=64, help='input batch size')\n","# parser.add_argument('--imageSize', type=int, default=64, help='the height / width of the input image to network')\n","# parser.add_argument('--nz', type=int, default=100, help='size of the latent z vector')\n","# parser.add_argument('--ngf', type=int, default=64)\n","# parser.add_argument('--ndf', type=int, default=64)\n","# parser.add_argument('--niter', type=int, default=600, help='number of epochs to train for')\n","# parser.add_argument('--lr', type=float, default=0.0002, help='learning rate, default=0.0002')\n","# parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n","# parser.add_argument('--cuda', action='store_true', help='enables cuda')\n","# parser.add_argument('--ngpu', type=int, default=1, help='number of GPUs to use')\n","# parser.add_argument('--netG', default='', help=\"path to netG (to continue training)\")\n","# parser.add_argument('--netD', default='', help=\"path to netD (to continue training)\")\n","# parser.add_argument('--outf', default='.', help='folder to output images and model checkpoints')\n","# parser.add_argument('--manualSeed', type=int, help='manual seed')\n","\n","# parser.add_argument('--cls', action='store_true', help='activates cls run')\n","# parser.add_argument('--desc_per_img', type=int, default=1, help='# of descriptions per image. max=10')\n","# parser.add_argument('--incl_stopwords', type=bool, default=False, help='include word vectors for stopwords in text encodings')\n","\n","# custom weights initialization called on netG and netD\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        m.weight.data.normal_(0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        m.weight.data.normal_(1.0, 0.02)\n","        m.bias.data.fill_(0)\n","# START\n","\n","# opt = parser.parse_args()\n","# print(opt)\n","opt.display_options()\n","\n","try:\n","    os.makedirs(opt.outf)\n","except OSError:\n","    pass\n","\n","if opt.manualSeed is None:\n","    opt.manualSeed = random.randint(1, 10000)\n","print(\"Random Seed: \", opt.manualSeed)\n","random.seed(opt.manualSeed)\n","torch.manual_seed(opt.manualSeed)\n","\n","cudnn.benchmark = True\n","\n","if torch.cuda.is_available() and not opt.cuda:\n","    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n","\n","# #dataset = TTI_Dataset()\n","# dataset = Birds(\n","#             descriptions_per_image=opt.desc_per_img,\n","#             incl_stopwords=opt.incl_stopwords\n","#         )\n","nc=3\n","\n","print('loaded dataset')\n","assert dataset\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batchSize,\n","                                         shuffle=False, num_workers=int(opt.workers))\n","#                                          shuffle=True, num_workers=int(opt.workers))\n","\n","device = torch.device(\"cuda:0\" if opt.cuda else \"cpu\")\n","ngpu = int(opt.ngpu) # num gpus\n","nz = int(opt.nz) # size of noise vector\n","ngf = int(opt.ngf) # number of filters in generator layer\n","ndf = int(opt.ndf) # number of filters in discriminator layer\n","\n","netG = Generator(ngpu).to(device)\n","netG.apply(weights_init)\n","if opt.netG != '':\n","    netG.load_state_dict(torch.load(opt.netG))\n","print(netG)\n","\n","netD = Discriminator(ngpu).to(device)\n","netD.apply(weights_init)\n","if opt.netD != '':\n","    netD.load_state_dict(torch.load(opt.netD))\n","print(netD)\n","\n","criterion = nn.BCELoss()\n","\n","fixed_noise = torch.randn(opt.batchSize, nz, 1, 1, device=device)\n","real_label = 1\n","fake_label = 0\n","\n","loss_by_epoch_D = np.zeros(opt.niter, dtype=np.float_)\n","loss_by_epoch_G = np.zeros(opt.niter, dtype=np.float_)\n","\n","# setup optimizer\n","optimizerD = optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n","print('starting epochs')\n","starting_time = time.time()\n","for epoch in range(opt.niter):\n","    etime = time.time()\n","    # right image, right embed, wrong embed\n","    for i, (real_image, real_embedding, wrong_embedding) in enumerate(dataloader, 0):\n","        if opt.cuda:\n","            real_image = real_image.to(device)\n","            real_embedding = real_embedding.to(device)\n","            wrong_embedding = wrong_embedding.to(device)\n","\n","        ############################\n","        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","        ###########################\n","        # train with real image, real embed\n","        netD.zero_grad()\n","\n","        batch_size = real_image.size(0)\n","        label = torch.full((batch_size,), real_label, device=device)\n","        output = netD(real_image, real_embedding)\n","        errD_real = criterion(output, label)\n","        errD_real.backward()\n","        D_x = output.mean().item()\n","\n","        if opt.cls:\n","            # cls real img, fake embed\n","            label.fill_(fake_label)\n","            output = netD(real_image, wrong_embedding)\n","            errD_wrong = criterion(output, label)\n","            errD_wrong.backward()\n","\n","        # train with fake\n","        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n","        fake = netG(real_embedding, noise)\n","        label.fill_(fake_label)\n","        output = netD(fake.detach(), real_embedding)\n","        errD_fake = criterion(output, label)\n","        errD_fake.backward()\n","\n","        if opt.cls:\n","            errD = errD_real + errD_fake + errD_wrong\n","        else:\n","            errD = errD_real + errD_fake\n","\n","        D_G_z1 = output.mean().item()\n","        optimizerD.step()\n","\n","        ############################\n","        # (2) Update G network: maximize log(D(G(z)))\n","        ###########################\n","        netG.zero_grad()\n","        label.fill_(real_label)  # fake labels are real for generator cost\n","        output = netD(fake, real_embedding)\n","        errG = criterion(output, label)\n","        errG.backward()\n","        D_G_z2 = output.mean().item()\n","        optimizerG.step()\n","\n","        if i % 20 == 0:\n","          print(\"[{}/{}][{}/{}] Loss_D: {:.4f} | Loss_G: {:.4f} | D(x) {:.4f} | D(G(z)): {:.8f}\"\n","          .format(epoch, opt.niter, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1 / D_G_z2))\n","\n","        if i == len(dataloader)-2: # 2nd to last iteration in epoch\n","            vutils.save_image(real_image,\n","                  '%s/real_samples.png' % opt.outf,\n","                  normalize=True)\n","            fake = netG(real_embedding ,fixed_noise)\n","            print('saving netG img to %s/fake_samples_epoch%03d_dpi%d_sw%d_bs%d.png' % (\n","                opt.outf,\n","                epoch,\n","                opt.desc_per_img,\n","                opt.incl_stopwords,\n","                opt.batchSize))\n","            vutils.save_image(fake.detach(),\n","                  '%s/fake_samples_epoch%03d_dpi%d_sw%d_bs%d_lr%f_beta%f.png' % (\n","                      opt.outf,\n","                      epoch,\n","                      opt.desc_per_img,\n","                      opt.incl_stopwords,\n","                      opt.batchSize,\n","                      opt.lr,\n","                      opt.beta1),\n","                  normalize=True)\n","    print(\"Epoch time:\", time.time() - etime)\n","    # do checkpointing\n","    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (opt.outf, epoch))\n","    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (opt.outf, epoch))\n","\n","    loss_by_epoch_D[epoch] = errD.item()\n","    loss_by_epoch_G[epoch] = errG.item()\n","    \n","ending_time = time.time()\n","print(\"Total runtime for epochs\", ending_time - starting_time)\n","\n","print(\"saving progress to %s/loss_by_epoch_D_dpi%d_sw%d_lr%f_beta%f.out\" % \n","      (opt.outf,\n","       opt.desc_per_img,\n","       opt.incl_stopwords,\n","       opt.lr,\n","       opt.beta1\n","      ))\n","np.savetxt(\"%s/loss_by_epoch_D_descperimg_%d_stopwords_%d.out\" %\n","           (opt.outf,\n","            opt.desc_per_img,\n","            opt.incl_stopwords,\n","            opt.lr,\n","            opt.beta1\n","           ), loss_by_epoch_D)\n","\n","print(\"saving progress to %s/loss_by_epoch_G_dpi%d_sw%d_lr%f_beta%f.out\" % \n","      (opt.outf,\n","       opt.desc_per_img,\n","       opt.incl_stopwords,\n","       opt.lr,\n","       opt.beta1\n","      ))\n","np.savetxt(\"%s/loss_by_epoch_G_dpi%d_sw%d_lr%f_beta%f.out\" %\n","           (opt.outf,\n","            opt.desc_per_img,\n","            opt.incl_stopwords,\n","            opt.lr,\n","            opt.beta1\n","           ), loss_by_epoch_G)"],"execution_count":0,"outputs":[]}]}